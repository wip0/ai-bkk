{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "modelFolder = \"./face_detection_model\"\n",
    "protoFile = os.path.sep.join([modelFolder, \"deploy.prototxt\"])\n",
    "modelFile = os.path.sep.join([modelFolder, \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "# detector = cv2.dnn.readNetFromCaffe(protoFile, modelFile)\n",
    "\n",
    "# Prepare image dataset\n",
    "dataSetFolder = \"./dataset\"\n",
    "# imageFiles = list(paths.list_images(dataSetFolder))\n",
    "\n",
    "# Prepare embedded\n",
    "embeddedFile = \"./openface_nn4.small2.v1.t7\"\n",
    "# embedder = cv2.dnn.readNetFromTorch(embeddedFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "totalImage=15\n> processing image 01/15 => kitty\n  - face found.  Confidence=1.00\n> processing image 02/15 => kitty\n  - face found.  Confidence=0.99\n> processing image 03/15 => kitty\n  - face found.  Confidence=1.00\n> processing image 04/15 => kitty\n  - face found.  Confidence=1.00\n> processing image 05/15 => kitty\n  - face found.  Confidence=1.00\n> processing image 06/15 => kitty\n  - face found.  Confidence=1.00\n> processing image 07/15 => unknown\n  - face found.  Confidence=0.98\n> processing image 08/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 09/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 10/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 11/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 12/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 13/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 14/15 => unknown\n  - face found.  Confidence=1.00\n> processing image 15/15 => unknown\n  - face found.  Confidence=1.00\n[INFO] serializing 15 encodings\n>>> output/embeddings.pickle\n"
    }
   ],
   "source": [
    "# Set Output\n",
    "outputFile = \"output/embeddings.pickle\"\n",
    "\n",
    "knownLabels = []\n",
    "knownEmbeddings = []\n",
    "# Prepare parameters\n",
    "minimumConfidence = 0.5\n",
    "faceMinWidth, faceMinHeight = 20, 20\n",
    "faceOutputWidth, faceOutputHeight = 96, 96\n",
    "faceScale = 1.0 / 255\n",
    "faceMean = (0, 0, 0)\n",
    "# Resize image to 300x300 pixels to blob object and normalizing\n",
    "resizedWidth, resizedHeight = 300, 300\n",
    "scale = 1.0\n",
    "mean = (104.0, 177.0, 123.0)\n",
    "#########################################\n",
    "# Load face model \n",
    "detector = cv2.dnn.readNetFromCaffe(protoFile, modelFile)\n",
    "\n",
    "# Load embedding model\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddedFile)\n",
    "\n",
    "# List all images in dataset\n",
    "imageFiles = list(paths.list_images(dataSetFolder))\n",
    "totalImage = len(imageFiles)\n",
    "print(\"totalImage={0}\".format(totalImage))\n",
    "\n",
    "# Process image dataset\n",
    "for (i, imageFile) in enumerate(imageFiles):\n",
    "    label = imageFile.split(os.path.sep)[-2]\n",
    "    print(\"> processing image {0:02d}/{1:02d} => {2}\".format(i + 1, totalImage, label))\n",
    "    # Load image and resize while maintaining the aspect ratio\n",
    "    image = cv2.imread(imageFile)\n",
    "    image = imutils.resize(image, width=600)\n",
    "    (orgHeight, orgWidth) = image.shape[:2]\n",
    "    resizedImage = cv2.resize(image, (resizedWidth, resizedHeight))\n",
    "    # Create a blob image\n",
    "    inputBlob = cv2.dnn.blobFromImage(resizedImage, scale, (resizedWidth, resizedHeight), mean, swapRB=False, crop=False)\n",
    "\n",
    "    # Apply a face detector\n",
    "    detector.setInput(inputBlob)\n",
    "    detections = detector.forward()\n",
    "\n",
    "    # If there is one face found at least\n",
    "    if len(detections) > 0:\n",
    "        # we're making the assumption that each image has only ONE face\n",
    "        k = np.argmax(detections[0, 0, :, 2])\n",
    "        confidence = detections[0, 0, k, 2]\n",
    "        if confidence > minimumConfidence:\n",
    "            # Compute face bounding box\n",
    "            box = detections[0, 0, k, 3:7] * np.array([orgWidth, orgHeight, orgWidth, orgHeight])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Extract the face ROI\n",
    "            face = image[startY:endY, startX:endX]\n",
    "            (faceHeight, faceWidth) = face.shape[:2]\n",
    "\n",
    "            # Face size is larger than the minimum\n",
    "            if faceWidth < faceMinWidth or faceHeight < faceMinHeight:\n",
    "                continue\n",
    "\n",
    "            print(\"  - face found.  Confidence={0:.2f}\".format(confidence))\n",
    "            \n",
    "            # Create a blob from the face ROI\n",
    "            faceBlob = cv2.dnn.blobFromImage(face, faceScale, (faceOutputWidth, faceOutputHeight), faceMean, swapRB=True, crop=False)\n",
    "            # Pass face blob to embedding model to obtain the 128-d quantification of the face\n",
    "            embedder.setInput(faceBlob)\n",
    "            vec = embedder.forward()\n",
    "\n",
    "            # Add the detection\n",
    "            knownLabels.append(label)\n",
    "            knownEmbeddings.append(vec.flatten())\n",
    "# Dump all embeddings to disk            \n",
    "print(\"[INFO] serializing {0} encodings\".format(len(knownEmbeddings)))\n",
    "data = { \"embeddings\": knownEmbeddings, \"labels\": knownLabels }\n",
    "# Write to file\n",
    "print(\">>> {0}\".format(outputFile))\n",
    "fp = open(outputFile, \"wb\")\n",
    "fp.write(pickle.dumps(data))\n",
    "fp.close()\n",
    ""
   ]
  }
 ]
}